{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVuSxJ8xIWobwT1pf6hoyZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Surajkr1166/Data-science-hands-on-model-Pyspyder/blob/main/Linear_regression_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiple Linear Regression**\n",
        "## **Housing Case Study**\n",
        "\n",
        "#### **Problem Statement:**\n",
        "\n",
        "Consider a real estate company that has a dataset containing the prices of properties in the Delhi region. It wishes to use the data to optimise the sale prices of the properties based on important factors such as area, bedrooms, parking, etc.\n",
        "\n",
        "Essentially, the company wants â€”\n",
        "\n",
        "\n",
        "- To identify the variables affecting house prices, e.g. area, number of rooms, bathrooms, etc.\n",
        "\n",
        "- To create a linear model that quantitatively relates house prices with variables such as number of rooms, area, number of bathrooms, etc.\n",
        "\n",
        "- To know the accuracy of the model, i.e. how well these variables can predict house prices.\n",
        "\n",
        "**So interpretation is important!**"
      ],
      "metadata": {
        "id": "rY_JauXnWzQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Reading and Understanding the Data\n",
        "\n",
        "Let us first import NumPy and Pandas and read the housing dataset"
      ],
      "metadata": {
        "id": "lbypLEAQXLmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the essesntial libraries\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "rYjK_MMUXRHV"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "rikj0VORXdF0",
        "outputId": "df83b788-d21d-46d1-9e62-7ee3a3142825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ed28dab-6f04-472f-a09e-8330f2f94e37\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0ed28dab-6f04-472f-a09e-8330f2f94e37\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "housing = pd.read_csv(\"Housing.csv\")"
      ],
      "metadata": {
        "id": "K8tybaJbXrmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the head of the dataset or interal columns and rows\n",
        "housing.head()"
      ],
      "metadata": {
        "id": "zDgXUSiiX0Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect the various aspects of the housing dataframe\n"
      ],
      "metadata": {
        "id": "Lp9rnmK9YUl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.shape"
      ],
      "metadata": {
        "id": "fxEBo6KNX37x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#it mainly used to give concise summary for the data frame\n",
        "housing.info()"
      ],
      "metadata": {
        "id": "wIwN8HD2YafT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "871e353f"
      },
      "source": [
        "#it gives the descriptive statistics value but only on numeric column\n",
        "housing.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Visualising the Data\n",
        "\n",
        "Let's now spend some time doing what is arguably the most important step - **understanding the data**.\n",
        "- If there is some obvious multicollinearity going on, this is the first place to catch it\n",
        "- Here's where you'll also identify if some predictors directly have a strong association with the outcome variable\n",
        "\n",
        "We'll visualise our data using `matplotlib` and `seaborn`."
      ],
      "metadata": {
        "id": "poNLm_oWZGAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#essential libraries for the data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "IdT_OOPPY3Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualising Numeric Variables\n",
        "\n",
        "Let's make a pairplot of all the numeric variables"
      ],
      "metadata": {
        "id": "FWPfQMzoZYyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(housing)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7igAmDtwZR0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualising Categorical Variables\n",
        "\n",
        "As you might have noticed, there are a few categorical variables as well. Let's make a boxplot for some of these variables."
      ],
      "metadata": {
        "id": "_AVr78m_ZmXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 12))\n",
        "plt.subplot(2,3,1)\n",
        "sns.boxplot(x = 'mainroad', y = 'price', data = housing)\n",
        "plt.subplot(2,3,2)\n",
        "sns.boxplot(x = 'guestroom', y = 'price', data = housing)\n",
        "plt.subplot(2,3,3)\n",
        "sns.boxplot(x = 'basement', y = 'price', data = housing)\n",
        "plt.subplot(2,3,4)\n",
        "sns.boxplot(x = 'hotwaterheating', y = 'price', data = housing)\n",
        "plt.subplot(2,3,5)\n",
        "sns.boxplot(x = 'airconditioning', y = 'price', data = housing)\n",
        "plt.subplot(2,3,6)\n",
        "sns.boxplot(x = 'furnishingstatus', y = 'price', data = housing)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FRc-3YtAZbnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10, 5))\n",
        "sns.boxplot(x = 'furnishingstatus', y = 'price', hue = 'airconditioning', data = housing)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YN-1angCZqrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Data Preparation\n",
        "- You can see that your dataset has many columns with values as 'Yes' or 'No'.\n",
        "\n",
        "- But in order to fit a regression line, we would need numerical values and not string. Hence, we need to convert them to 1s and 0s, where 1 is a 'Yes' and 0 is a 'No'."
      ],
      "metadata": {
        "id": "yUyiwGSLZ3gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of variables to map\n",
        "\n",
        "varlist =  ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "\n",
        "# Defining the map function\n",
        "def binary_map(x):\n",
        "    return x.map({'yes': 1, \"no\": 0})\n",
        "\n",
        "# Applying the function to the housing list\n",
        "housing[varlist] = housing[varlist].apply(binary_map)"
      ],
      "metadata": {
        "id": "XcZt4ircZzSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the housing dataframe now\n",
        "\n",
        "housing.head()"
      ],
      "metadata": {
        "id": "qfGag3JmaAvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dummy Variables\n",
        "The variable `furnishingstatus` has three levels. We need to convert these levels into integer as well.\n",
        "\n",
        "For this, we will use something called `dummy variables`."
      ],
      "metadata": {
        "id": "jPJU1jRdaHY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dummy variables for the feature 'furnishingstatus' and store it in a new variable - 'status'\n",
        "status = pd.get_dummies(housing['furnishingstatus'])"
      ],
      "metadata": {
        "id": "To6adQZ4aDfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what the dataset 'status' looks like\n",
        "status.head()"
      ],
      "metadata": {
        "id": "XPGa6pQuaOKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, you don't need three columns. You can drop the `furnished` column, as the type of furnishing can be identified with just the last two columns where â€”\n",
        "- `00` will correspond to `furnished`\n",
        "- `01` will correspond to `unfurnished`\n",
        "- `10` will correspond to `semi-furnished`"
      ],
      "metadata": {
        "id": "kxKpWQKBaURT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's drop the first column from status df using 'drop_first = True'\n",
        "\n",
        "status = pd.get_dummies(housing['furnishingstatus'], drop_first = True)"
      ],
      "metadata": {
        "id": "TE9qcP6EaQmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the results to the original housing dataframe\n",
        "\n",
        "housing = pd.concat([housing, status], axis = 1)"
      ],
      "metadata": {
        "id": "ucMWqsQJaXLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's see the head of our dataframe.\n",
        "\n",
        "housing.head()"
      ],
      "metadata": {
        "id": "zLT5CF1-aaT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop 'furnishingstatus' as we have created the dummies for it\n",
        "\n",
        "housing.drop(['furnishingstatus'], axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "FbsMMzoXadMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing.info()"
      ],
      "metadata": {
        "id": "l2JTLKZwagYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the correlation coefficients to see which variables are highly correlated\n",
        "\n",
        "plt.figure(figsize = (16, 10))\n",
        "sns.heatmap(housing.corr(), annot = True, cmap=\"YlGnBu\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nfpBYVH2akrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#As you might have noticed, `area` seems to the correlated to `price` the most. Let's see a pairplot for `area` vs `price`.\n",
        "plt.figure(figsize=[6,6])\n",
        "plt.scatter(housing.area, housing.price)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "td_VUXmZaoLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rescaling the Features\n",
        "\n",
        "As you saw in the demonstration for Simple Linear Regression, scaling doesn't impact your model. Here we can see that except for `area`, all the columns have small integer values. So it is extremely important to rescale the variables so that they have a comparable scale. If we don't have comparable scales, then some of the coefficients as obtained by fitting the regression model might be very large or very small as compared to the other coefficients. This might become very annoying at the time of model evaluation. So it is advised to use standardization or normalization so that the units of the coefficients obtained are all on the same scale. As you know, there are two common ways of rescaling:\n",
        "\n",
        "1. Min-Max scaling\n",
        "2. Standardisation (mean-0, sigma-1)\n",
        "\n",
        "This time, we will use MinMax scaling."
      ],
      "metadata": {
        "id": "GqWPVobna6Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize numeric variables - Scales all numeric features so they are comparable (mean = 0, std = 1).\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()"
      ],
      "metadata": {
        "id": "PTX5F4gUa0Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled = scaler.fit_transform(housing.drop(\"price\", axis=1))"
      ],
      "metadata": {
        "id": "jg_YMvC7a9KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=X_scaled\n",
        "y=housing[\"price\"]"
      ],
      "metadata": {
        "id": "De1rHFFVbD57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "3SZy-z7CbGub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Splitting the Data into Training and Testing Sets\n",
        "\n",
        "As you know, the first basic step for regression is performing a train-test split."
      ],
      "metadata": {
        "id": "Kj-NChUrbPun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "XXQjjT2MbMwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Step 5:Train a simple model (Linera Regression)"
      ],
      "metadata": {
        "id": "thFs2h77bVuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The model learns the relationship between features (X_train) and churn (y_train).\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "H_587824bSw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get results (coefficients and intercept)\n",
        "print(f\"Intercept: {model.intercept_}\")\n",
        "print(f\"Coefficients: {model.coef_}\")"
      ],
      "metadata": {
        "id": "QP0m1nbbbZE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Make predictions\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "wmgUvzMjbcZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "cHsFaXUebfua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(y_pred-y_test, kind='kde')"
      ],
      "metadata": {
        "id": "3bSFvUVDbmOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "variance is very low means its a good model, -4 to +4"
      ],
      "metadata": {
        "id": "JkYwi0Jpb7rG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "LhiEbZVrb4N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate R squared\n",
        "r2=r2_score(y_pred,y_test)"
      ],
      "metadata": {
        "id": "nHpeE21Wb_wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2"
      ],
      "metadata": {
        "id": "EmIllQTtcCUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get n (number of observations) and p (number of features)\n",
        "n = X.shape[0]  # Number of samples\n",
        "p = X.shape[1]  # Number of features\n",
        "\n",
        "# Calculate Adjusted R-squared\n",
        "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "print(f\"R-squared: {r2:.4f}\")\n",
        "print(f\"Adjusted R-squared: {adjusted_r2:.4f}\")"
      ],
      "metadata": {
        "id": "rvlVVHURcFuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EakakugucIq1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}